{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_nyisocom_csv(folder_path):\n",
    "    '''\n",
    "    read all csv data, which is located in two-level folder (year-month and day)\n",
    "    input: the path of the folder includes year-month folders\n",
    "    output: a dataframe consist of all rows read from csv\n",
    "    '''\n",
    "    year_text = [str(i) for i in range(2001,2024)]\n",
    "    month_text = [f\"{i:02}\" for i in range(1, 13)]\n",
    "    day_text = [f\"{i:02}\" for i in range(1, 32)]\n",
    "\n",
    "    data_ls = []\n",
    "    for year in year_text:\n",
    "        for month in month_text:\n",
    "            for day in day_text:\n",
    "                try:\n",
    "                    df = pd.read_csv(path+year+month+'01palIntegrated_csv/'+year+month+day+'palIntegrated.csv')\n",
    "                    df = df.loc[:,['Time Stamp', 'Name', 'Integrated Load']]\n",
    "                    data_ls.append(df)\n",
    "                except FileNotFoundError:\n",
    "                    # print(f\"File not found: {year}{month}{day}. Skipping to the next iteration.\")\n",
    "                    pass\n",
    "    data = pd.concat(data_ls, ignore_index=True)            \n",
    "    print(f'所有資料筆數: {data.shape}')\n",
    "\n",
    "    return(data)\n",
    "\n",
    "def split_NYC_LONGIL(data):\n",
    "    '''\n",
    "    before 2005/1/31, NYC and LONGIL are recorded in the same row, this function can split them into 2 rows\n",
    "    reminder: some of them are duplicated, but this function does not deal with duplicates\n",
    "    input: a dataframe from read_nyisocom_csv\n",
    "    output: a dataframe\n",
    "    '''\n",
    "    indices_to_split = data[data['Name'] == 'N.Y.C._LONGIL'].index # 找到含有\"N.Y.C._LONGIL\"的行的索引\n",
    "    print(len(indices_to_split))\n",
    "    split_rows = pd.DataFrame(columns=data.columns) # 创建一个新的 DataFrame 存放拆分后的行\n",
    "\n",
    "    for index in indices_to_split: # 遍历索引，将每个含有\"N.Y.C._LONGIL\"的行拆分为两行\n",
    "\n",
    "        original_row = data.loc[index]\n",
    "        \n",
    "        # 第一行的 Name 为 \"N.Y.C\"\n",
    "        split_row_1 = pd.DataFrame([original_row.values], columns=data.columns)\n",
    "        split_row_1['Name'] = 'N.Y.C.'\n",
    "        split_rows = pd.concat([split_rows, split_row_1], ignore_index=True)\n",
    "        \n",
    "        # 第二行的 Name 为 \"LONGIL\"\n",
    "        split_row_2 = pd.DataFrame([original_row.values], columns=data.columns)\n",
    "        split_row_2['Name'] = 'LONGIL'\n",
    "        split_rows = pd.concat([split_rows, split_row_2], ignore_index=True)\n",
    "\n",
    "    data = data.drop(indices_to_split) # 删除原 DataFrame 中含有\"N.Y.C._LONGIL\"的行\n",
    "    data = pd.concat([data, split_rows], ignore_index=True) # 将拆分后的行插入原 DataFrame 中的相同位置\n",
    "    data = data.sort_values(by=['Time Stamp', 'Name']).reset_index(drop=True) # 按照 Time Stamp 和 Name 进行排序\n",
    "\n",
    "    print(f'資料筆數: {data.shape}')\n",
    "    return(data)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "所有資料筆數: (2142341, 3)\n",
      "31839\n",
      "資料筆數: (2174180, 3)\n"
     ]
    }
   ],
   "source": [
    "# path = '/Users/tina/Documents/3_Research/202309_NYISO/NYISOCOM_datasets/'\n",
    "path = '/home/hchuang/Documents/Project/SSSD_CP/src/datasets/NYISO/NYISOCOM_datasets/'\n",
    "\n",
    "# read all csv data from folders\n",
    "raw_data = read_nyisocom_csv(folder_path = path)\n",
    "# before 2005/1/31, NYC and LONGIL are recorded in the same row, split them into 2 rows\n",
    "data = split_NYC_LONGIL(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column names\n",
    "column_mapping = {'Time Stamp': 'Date', 'Name': 'Zone', 'Integrated Load': 'Load'}\n",
    "data.rename(columns=column_mapping, inplace=True)\n",
    "# change the date format\n",
    "data['Date'] = pd.to_datetime(data['Date'], format='%m/%d/%Y %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export a pickle file\n",
    "data.to_pickle('/home/hchuang/Documents/Project/SSSD_CP/src/datasets/NYISO/pickle/load_nyisocom.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
